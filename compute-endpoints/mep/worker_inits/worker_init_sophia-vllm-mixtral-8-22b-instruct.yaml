{% raw -%}
    worker_init: |
      # Source the common script
      source /home/openinference_svc/sophia_common_scripts.sh
      # Setup the environment
      setup_environment

      # Define model parameters
      model_name="mistralai/Mixtral-8x22B-Instruct-v0.1"
      framework="vllm"
      cluster="sophia"
      model_command="vllm serve ${model_name} --host 127.0.0.1 --port 8000 \
      --tensor-parallel-size 8 --gpu-memory-utilization 0.95 --max-model-len 32768  \
      --disable-log-stats  --enable-chunked-prefill  --multi-step-stream-outputs False \
      --disable-log-requests --ssl-keyfile ~/certificates/mykey.key --ssl-certfile ~/certificates/mycert.crt"
      logfile="$PWD/logfile_sophia-vllm-${model_name}_$(hostname).log"

      # Initialize retry counters for each model
      retry_counter_model=0

      # Loop to start models and restart if any model fails
      while true; do
          echo "Starting models sequence..."
          # Start first model
          if ! start_model "$model_name" "$model_command" "$logfile" retry_counter_model; then
              continue  # Restart from the beginning if this fails
          fi    
          echo "All models started successfully."
          break  # Exit the loop if all models start successfully
      done
{% endraw %}