{% raw -%}
    worker_init: |
      # Source the common script
      source /home/openinference_svc/sophia_common_scripts.sh
      # Setup the environment
      setup_environment

      # Define model parameters
      model_name="mistralai/Mistral-Large-Instruct-2407"
      framework="vllm"
      cluster="sophia"
      model_command="vllm serve /eagle/argonne_tpc/model_weights/Mistral-Large-Instruct-2407 --host 127.0.0.1 --port 8000 \
      --tensor-parallel-size 8 --gpu-memory-utilization 0.95 --max-model-len 65536 \
      --disable-log-stats  --enable-chunked-prefill  --multi-step-stream-outputs False \
      --served-model-name ${model_name}  \
      --disable-log-requests --ssl-keyfile ~/certificates/mykey.key --ssl-certfile ~/certificates/mycert.crt"
      logfile="$PWD/logfile_sophia-vllm-${model_name}_$(hostname).log"
      
      # Initialize retry counters for each model
      retry_counter_model_1=0

      # Loop to start models and restart if any model fails
      while true; do
          echo "Starting models sequence..."
          # Start first model
          if ! start_model "$model_name" "$model_command" "$logfile" retry_counter_model_1; then
              continue  # Restart from the beginning if this fails
          fi    
          echo "All models started successfully."
          break  # Exit the loop if all models start successfully
      done
{% endraw %}