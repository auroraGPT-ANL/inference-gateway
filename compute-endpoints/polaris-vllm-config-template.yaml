amqp_port: 443
display_name: polaris-vllm-meta-llama-3-70b-instruct
engine:
  type: GlobusComputeEngine
  max_retries_on_system_failure: 2
  max_workers_per_node: 4
  job_status_kwargs:
    max_idletime: 600
  address:
    type: address_by_interface
    ifname: bond0
  provider:
    type: PBSProProvider
    launcher:
      type: SimpleLauncher
    account: DataServicePrototype
    cpus_per_node: 128
    select_options: ngpus=4
    scheduler_options: '#PBS -l filesystems=home:eagle'
    queue: 'debug'
    init_blocks: 0
    max_blocks: 1
    min_blocks: 0
    nodes_per_block: 1
    walltime: 00:60:00
    worker_init: |
      module use /soft/modulefiles
      module load conda
      conda activate ~/envs/vllmv0.5.4-polaris-env
      module use /soft/spack/base/0.7.1/install/modulefiles/Core
      module load gcc/11.4.0
      module load cudatoolkit-standalone
      export HF_DATASETS_CACHE="/eagle/argonne_tpc/model_weights/"
      export HF_HOME="/eagle/argonne_tpc/model_weights/"
      export RAY_TMPDIR="/tmp"
      export RAYON_NUM_THREADS=4
      export RUST_BACKTRACE=1
      export VLLM_WORKER_MULTIPROC_METHOD=fork
      (nohup vllm serve meta-llama/Meta-Llama-3-8B-Instruct --host 127.0.0.1 --port 8000 --tensor-parallel-size 4 --gpu-memory-utilization 0.95 --max-model-len 8192 --enforce-eager --ssl-keyfile ~/certificates/mykey.key --ssl-certfile ~/certificates/mycert.crt  > /home/openinference_svc/logfile_polaris-vllm-meta-llama-3-8b-instruct.log 2>&1 &) && while ! grep -q "INFO:     Application startup complete." /home/openinference_svc/logfile_polaris-vllm-meta-llama-3-8b-instruct.log; do sleep 1; done;
# Limit the functions UUID that can be execute
allowed_functions:
   - 3a060933-2297-403f-a9a0-1037d04a09bb
