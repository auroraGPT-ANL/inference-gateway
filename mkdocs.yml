site_name: FIRST Documentation
site_description: Federated Inference Resource Scheduling Toolkit - Documentation for deploying and using LLM inference as a service
site_author: Argonne National Laboratory
site_url: https://auroragpt-anl.github.io/inference-gateway/

repo_name: auroraGPT-ANL/inference-gateway
repo_url: https://github.com/auroraGPT-ANL/inference-gateway
edit_uri: edit/main/docs/

theme:
  name: material
  palette:
    # Light mode
    - media: "(prefers-color-scheme: light)"
      scheme: default
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-7
        name: Switch to dark mode
    # Dark mode
    - media: "(prefers-color-scheme: dark)"
      scheme: slate
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-4
        name: Switch to light mode
  font:
    text: Roboto
    code: Roboto Mono
  features:
    - navigation.tabs
    - navigation.sections
    - navigation.expand
    - navigation.top
    - navigation.tracking
    - search.suggest
    - search.highlight
    - content.code.copy
    - content.code.annotate
  icon:
    repo: fontawesome/brands/github

plugins:
  - search
  - minify:
      minify_html: true

markdown_extensions:
  - admonition
  - pymdownx.details
  - pymdownx.superfences
  - pymdownx.highlight:
      anchor_linenums: true
  - pymdownx.inlinehilite
  - pymdownx.snippets
  - pymdownx.tabbed:
      alternate_style: true
  - tables
  - attr_list
  - md_in_html
  - toc:
      permalink: true

nav:
  - Home: index.md
  - Administrator Guide:
      - Overview: admin-guide/index.md
      - Gateway Setup:
          - Docker Deployment: admin-guide/gateway-setup/docker.md
          - Bare Metal Setup: admin-guide/gateway-setup/bare-metal.md
          - Configuration Reference: admin-guide/gateway-setup/configuration.md
      - Inference Backend Setup:
          - Overview: admin-guide/inference-setup/index.md
          - Globus Compute + vLLM: admin-guide/inference-setup/globus-compute.md
          - Local vLLM Setup: admin-guide/inference-setup/local-vllm.md
          - Direct API Connection: admin-guide/inference-setup/direct-api.md
      - Deployment:
          - Kubernetes: admin-guide/deployment/kubernetes.md
          - Production Best Practices: admin-guide/deployment/production.md
      - Monitoring & Troubleshooting: admin-guide/monitoring.md
  - User Guide: user-guide/index.md
  - Reference:
      - Citation: reference/citation.md
      - API Endpoints: reference/api.md
      - Configuration Options: reference/config.md

extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/auroraGPT-ANL/inference-gateway
    - icon: fontawesome/solid/book
      link: https://doi.org/10.1145/3731599.3767346

copyright: Copyright &copy; 2025 Argonne National Laboratory - Apache 2.0 License

